{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b17b3f6bda8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitjs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'context'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import wfm\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path().resolve().parent\n",
    "input_path = root_path / \"data\" / \"input\"\n",
    "images_path = root_path / \"images\"\n",
    "output_path = root_path / \"output\"\n",
    "\n",
    "input_data = wfm.preprocessing.get_input_data(input_path)\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = input_data.fillna(\"0\")\n",
    "\n",
    "# --- Split data \n",
    "split_random_state = 42\n",
    "X = (\n",
    "    input_data.drop(columns=[\"wildfire\", \"id\", \"n_da単o\", \"geometry\", \"orientacio\", \"mant_viv\"])\n",
    "    .pipe(lambda df: pd.DataFrame(df))\n",
    ")\n",
    "# X = X.select_dtypes(\"number\")\n",
    "# from sklearn import preprocessing\n",
    "# target_encoder = preprocessing.LabelEncoder()\n",
    "# target_encoder.fit(input_data[\"n_da単o\"])\n",
    "# y = target_encoder.transform(input_data[\"n_da単o\"])\n",
    "y = input_data[\"n_da単o\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=split_random_state\n",
    ")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"{y_train.size} train records and {y_test.size} test records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Preprocessing\n",
    "# categorical_columns = X.select_dtypes(\"object\").columns.tolist()\n",
    "# numerical_columns = X.select_dtypes(\"number\").columns.tolist()\n",
    "# preprocessor = make_column_transformer(\n",
    "#     (OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
    "#     remainder=\"passthrough\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer.fit_transform(input_data[[\"fact_agua\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        ('cat', categorical_transformer, selector(dtype_include=\"category\"))\n",
    "    ]\n",
    ")\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.fit(X_train, y_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        y_pred_test,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Model\n",
    "# model = make_pipeline(\n",
    "#     # imputer,\n",
    "#     preprocessor,\n",
    "#     RandomForestClassifier(\n",
    "#         n_estimators=10,\n",
    "#         n_jobs=-1,\n",
    "#         random_state=42,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# _ = model.fit(X_train, y_train)\n",
    "# y_pred_test = model.predict(X_test)\n",
    "# print(\n",
    "#     classification_report(\n",
    "#         y_test,\n",
    "#         y_pred_test,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model.predict, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.TreeExplainer(model)\n",
    "# explainer = \n",
    "for i in range(X.shape[0]):\n",
    "    try:\n",
    "        shap_values = explainer.shap_values(X.iloc[i:])\n",
    "        print(\"i\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model.predict, X)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "explainer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model[\"preprocessor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"preprocessor\"].named_transformers_[\"cat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"classifier\"].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model[\"classifier\"].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'material',\n",
    " 'orientacio',\n",
    " 'prep_vivie',\n",
    " 'mant_viv',\n",
    " 'acceso_equ',\n",
    " 'ac_supresi',\n",
    " 'fact_agua'\n",
    "]\n",
    "numerical_columns = wfm.NUM_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = (model.named_steps['preprocessor']\n",
    "         .named_transformers_['cat'])\n",
    "feature_names = ohe.get_feature_names(input_features=categorical_columns)\n",
    "feature_names = np.r_[feature_names, numerical_columns]\n",
    "\n",
    "tree_feature_importances = (\n",
    "    model.named_steps['classifier'].feature_importances_)\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(feature_names))\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticklabels(feature_names[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(model, X_test, y_test, n_repeats=10,\n",
    "                                random_state=42, n_jobs=3)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_test.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(model, X_train, y_train, n_repeats=10,\n",
    "                                random_state=42, n_jobs=3)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_train.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    model[\"classifier\"].feature_importances_,\n",
    "    columns=['Coefficients'],\n",
    "    index=X.columns\n",
    ")\n",
    "\n",
    "feature_importances.sort_values(\"Coefficients\").plot(kind='barh', figsize=(9, 7))\n",
    "plt.title('Random Forest')\n",
    "plt.axvline(x=0, color='.5')\n",
    "# plt.subplots_adjust(left=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, RepeatedKFold, RepeatedStratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    scoring=[\"r2\", \"neg_root_mean_squared_error\"],\n",
    "    cv=RepeatedStratifiedKFold(n_splits=4, n_repeats=30, random_state=42),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "coefs = pd.DataFrame(\n",
    "    [est.feature_importances_ for est in cv_model['estimator']],\n",
    "    columns=X.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All scorer objects follow the convention that higher return values are better than lower return values. Thus metrics which measure the distance between the model and the data, like metrics.mean_squared_error, are available as neg_mean_squared_error which return the negated value of the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = pd.DataFrame({\"Train\": cv_model['train_r2'], \"Test\": cv_model['test_r2']})\n",
    "plt.figure(figsize=(10, 9))\n",
    "sns.boxplot(data=cv_scores, orient='v', color='cyan', saturation=0.5)\n",
    "plt.ylabel('Score')\n",
    "plt.title('R2 Score for train and test sets')\n",
    "# plt.subplots_adjust(left=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = pd.DataFrame({\"Train\": cv_model['train_neg_root_mean_squared_error'], \"Test\": cv_model['test_neg_root_mean_squared_error']})\n",
    "plt.figure(figsize=(10, 9))\n",
    "sns.boxplot(data=cv_scores, orient='v', color='cyan', saturation=0.5)\n",
    "plt.ylabel('Score')\n",
    "plt.title('RMSE for train and test sets')\n",
    "# plt.subplots_adjust(left=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "# sns.swarmplot(data=coefs, orient='h', color='k', alpha=0.5)\n",
    "sns.boxplot(data=coefs, orient='h', color='cyan', saturation=0.5)\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.xlabel('Feature importance')\n",
    "plt.title('Feature importance and its variability')\n",
    "# plt.subplots_adjust(left=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_kernel_explainer = shap.KernelExplainer(model, X_train)\n",
    "# shap_values_single = shap_kernel_explainer.shap_values(x_test.iloc[0,:])\n",
    "# shap.force_plot(shap_kernel_explainer.expected_value[0],np.array(shap_values_single[0]), x_test.iloc[0,:],link='logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
